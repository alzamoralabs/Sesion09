{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea7d17f",
   "metadata": {},
   "source": [
    "### 1.ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b26cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv venvnb2 || source venvnb2\\Scripts\\activate\n",
    "!pip install -qU langchain-core langchain-ollama langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906dab6",
   "metadata": {},
   "source": [
    "Inicializamos el model con `phi3` local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fe33ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Inicializa el modelo Ollama LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d06182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b8ab23",
   "metadata": {},
   "source": [
    "Hay varias maneras de añadir mensajes a nuestra memoria. Usando el método save_context, podemos añadir una consulta del usuario (mediante la clave de entrada) y la respuesta de la IA (mediante la clave de salida). Para crear la siguiente conversación:\n",
    "\n",
    "- Usuario: Hola, me llamo Javier.\n",
    "- IA: ¡Hola Javier! Encantado de conocerte, soy un modelo de IA llamado Zeta.\n",
    "- Usuario: Estoy investigando los distintos tipos de memoria conversacional en LangChain.\n",
    "- IA: Qué interesante, ¿cuáles has estado explorando?\n",
    "- Usuario: He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.\n",
    "- IA: Suena bien. ¿Cuál es la diferencia entre ellos?\n",
    "- Usuario: La memoria tipo buffer guarda toda la conversación completa, ¿cierto?\n",
    "- IA: Exacto. ¿Y qué hace la memoria tipo buffer window?\n",
    "- Usuario: Esa guarda solo los últimos k mensajes y descarta el resto.\n",
    "- IA: ¡Muy útil para mantener el contexto sin saturar el modelo!\n",
    "\n",
    "Entonces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d04007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hola, me llamo Javier.\"},\n",
    "    {\"output\": \"¡Hola Javier! Encantado de conocerte, soy un modelo de IA llamado Zeta.\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"Estoy investigando los distintos tipos de memoria conversacional en LangChain.\"},\n",
    "    {\"output\": \"Qué interesante, ¿cuáles has estado explorando?\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.\"},\n",
    "    {\"output\": \"Suena bien. ¿Cuál es la diferencia entre ellos?\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"La memoria tipo buffer guarda toda la conversación completa, ¿cierto?\"},\n",
    "    {\"output\": \"Exacto. ¿Y qué hace la memoria tipo buffer window?\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"Esa guarda solo los últimos k mensajes y descarta el resto.\"},\n",
    "    {\"output\": \"¡Muy útil para mantener el contexto sin saturar el modelo!\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77f843ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hola, me llamo Javier.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='¡Hola Javier! Encantado de conocerte, soy un modelo de IA llamado Zeta.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Estoy investigando los distintos tipos de memoria conversacional en LangChain.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Qué interesante, ¿cuáles has estado explorando?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Hola, me llamo Javier.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='¡Hola Javier! Encantado de conocerte, soy un modelo de IA llamado Zeta.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Estoy investigando los distintos tipos de memoria conversacional en LangChain.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Qué interesante, ¿cuáles has estado explorando?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedcc438",
   "metadata": {},
   "source": [
    "Con esto, ya tenemos nuestra memoria tipo buffer lista.\n",
    "Antes de conectarla al LLM, revisemos otra forma de agregar mensajes a la memoria.\n",
    "\n",
    "En lugar de guardar el contexto completo de una conversación, esta alternativa permite añadir los mensajes de manera individual, tanto del usuario como de la IA, utilizando los métodos add_user_message y add_ai_message.\n",
    "\n",
    "Si quisiéramos replicar lo que hicimos anteriormente, lo haríamos así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b84b286f",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hola, me llamo Javier.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='¡Hola Javier! Encantado de conocerte, soy un modelo de IA llamado Zeta.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Estoy investigando los distintos tipos de memoria conversacional en LangChain.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Qué interesante, ¿cuáles has estado explorando?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message(\"Hola, me llamo Javier.\")\n",
    "memory.chat_memory.add_ai_message(\"¡Hola Javier! Encantado de conocerte, soy un modelo de IA llamado Zeta.\")\n",
    "memory.chat_memory.add_user_message(\"Estoy investigando los distintos tipos de memoria conversacional en LangChain.\")\n",
    "memory.chat_memory.add_ai_message(\"Qué interesante, ¿cuáles has estado explorando?\")\n",
    "memory.chat_memory.add_user_message(\"He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.\")\n",
    "memory.chat_memory.add_ai_message(\"Suena bien. ¿Cuál es la diferencia entre ellos?\")\n",
    "memory.chat_memory.add_user_message(\"La memoria tipo buffer guarda toda la conversación completa, ¿cierto?\")\n",
    "memory.chat_memory.add_ai_message(\"Exacto. ¿Y qué hace la memoria tipo buffer window?\")\n",
    "memory.chat_memory.add_user_message(\"Esa guarda solo los últimos k mensajes y descarta el resto.\")\n",
    "memory.chat_memory.add_ai_message(\"¡Muy útil para mantener el contexto sin saturar el modelo!\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e9c3f",
   "metadata": {},
   "source": [
    "El resultado final es idéntico en ambos casos.  \n",
    "Para poder conectar esta memoria con nuestro modelo de lenguaje (LLM), necesitamos crear un objeto `ConversationChain`.\n",
    "\n",
    "Sin embargo, es importante tener en cuenta que esta clase ha quedado obsoleta y ha sido reemplazada por `RunnableWithMessageHistory`, la cual veremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a841a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51bdc5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hola, me llamo Javier.', additional_kwargs={}, response_metadata={}), AIMessage(content='¡Hola Javier! Encantado de conocerte, soy un modelo de IA llamado Zeta.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Estoy investigando los distintos tipos de memoria conversacional en LangChain.', additional_kwargs={}, response_metadata={}), AIMessage(content='Qué interesante, ¿cuáles has estado explorando?', additional_kwargs={}, response_metadata={}), HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}), AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}), HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}), AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}), AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={}), HumanMessage(content='de que te estaba hablando?', additional_kwargs={}, response_metadata={}), AIMessage(content='La conversación anterior se centró en la exploración de tipos de memoria conversacional en LangChain. Pude entender que estabas investigando dos tipos específicos: ConversationBufferMemory y ConversationBufferWindowMemory. Me contaste que la primera opción, Conversión Buffer Memory, guarda toda la conversación completa, mientras que la segunda, Conversación Buffer Window Memory, solo almacena los mensajes más recientes (con un límite de k mensajes) y los descarta el resto. ¿Quieres saber más sobre cómo funcionan estas memorias o si hay alguna otra pregunta específica que me gustaría ayudarte a responder?', additional_kwargs={}, response_metadata={}), HumanMessage(content='de que te estaba hablando?', additional_kwargs={}, response_metadata={}), AIMessage(content='Disculpa la confusión, Javier. Parece que hemos cambiado de tema en medio de la conversación. Estabas investigando los distintos tipos de memoria conversacional en LangChain y había mencionado ConversationBufferMemory y ConversationBufferWindowMemory. Sin embargo, no tengo información específica sobre cómo funcionan estas memorias ni puedo proporcionar detalles detallados sobre ellas en este momento. Si deseas saber más, puedo intentar buscar información adicional o ayudarte a explorar otros temas relacionados con LangChain y memoria conversacional. ¿Te gustaría que sigamos investigando sobre este tema o prefieres cambiar de tema?', additional_kwargs={}, response_metadata={})]\n",
      "Human: de que te estaba hablando? (dímelo de forma puntual y breve)\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"de que te estaba hablando? (dímelo de forma puntual y breve)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "196d0311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La conversación anterior se centró en la exploración de tipos de memoria conversacional en LangChain, específicamente ConversationBufferMemory y ConversationBufferWindowMemory. Estabas preguntando sobre las diferencias entre ellos y cómo funcionan.\n"
     ]
    }
   ],
   "source": [
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c8aa79",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory with RunnableWithMessageHistory\n",
    "Como se advierte, el tipo `ConversationBufferMemory` está a punto de quedar obsoleto. En su lugar, podemos usar la clase `RunnableWithMessageHistory` para implementar la misma funcionalidad.\n",
    "\n",
    "Al implementar `RunnableWithMessageHistory`, usaremos el **LangChain Expression Language (LCEL)**. Para ello, necesitamos definir nuestra plantilla de mensaje y los componentes LLM. Con el LLM ya nos enfocaremos en `ChatPromptTemplate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d8cbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "system_prompt = \"Eres un asistente muy útil llamado Zeta, respondes siempre de forma breve y puntual.\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3707aba",
   "metadata": {},
   "source": [
    "Esta es la forma en la que trabaja LangChain, concatena (a manera de una cadena justamente) cada uno de los componentes que luego llegan a una invocacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5772ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33516227",
   "metadata": {},
   "source": [
    "`RunnableWithMessageHistory` requiere que nuestro pipeline esté en un objeto `RunnableWithMessageHistory`.\n",
    "Este objeto, requiere de `get_session_history`, el cual requiere a su vez de una función que devuelva un objeto ChatMessageHistory basado en un ID de sesión.\n",
    "\n",
    "Definimos esta función nosotros mismos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2233268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "chat_map = {}\n",
    "def get_chat_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # Si no existe, crea un nuevo historial de chat en memoria\n",
    "        chat_map[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a4e65",
   "metadata": {},
   "source": [
    "También necesitamos indicar a nuestro runnable qué nombre de variable usar para el historial de chat (por ejemplo, history) y cuál para la consulta del usuario (por ejemplo, query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16767e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58b44b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola Javier, encantado de conocerte. ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"hola, me llamo Javier.\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbb25db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola Javier, tu nombre en nuestra base de datos es \"Javier\". No tengo información adicional sobre ti.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"Cuál es mi nombre?\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7a505",
   "metadata": {},
   "source": [
    "### 2.ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74a32d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=4, return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "185ccd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Estoy investigando los distintos tipos de memoria conversacional en LangChain.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Qué interesante, ¿cuáles has estado explorando?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.add_user_message(\"Hola, me llamo Javier.\")\n",
    "memory.chat_memory.add_ai_message(\"¡Hola Javier! Encantado de conocerte, soy un modelo de IA llamado Zeta.\")\n",
    "memory.chat_memory.add_user_message(\"Estoy investigando los distintos tipos de memoria conversacional en LangChain.\")\n",
    "memory.chat_memory.add_ai_message(\"Qué interesante, ¿cuáles has estado explorando?\")\n",
    "memory.chat_memory.add_user_message(\"He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.\")\n",
    "memory.chat_memory.add_ai_message(\"Suena bien. ¿Cuál es la diferencia entre ellos?\")\n",
    "memory.chat_memory.add_user_message(\"La memoria tipo buffer guarda toda la conversación completa, ¿cierto?\")\n",
    "memory.chat_memory.add_ai_message(\"Exacto. ¿Y qué hace la memoria tipo buffer window?\")\n",
    "memory.chat_memory.add_user_message(\"Esa guarda solo los últimos k mensajes y descarta el resto.\")\n",
    "memory.chat_memory.add_ai_message(\"¡Muy útil para mantener el contexto sin saturar el modelo!\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b6f13e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59a36cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Estoy investigando los distintos tipos de memoria conversacional en LangChain.', additional_kwargs={}, response_metadata={}), AIMessage(content='Qué interesante, ¿cuáles has estado explorando?', additional_kwargs={}, response_metadata={}), HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}), AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}), HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}), AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}), AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={})]\n",
      "Human: cual es mi nombre?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"cual es mi nombre?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ebadc3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento, pero no tengo suficiente información sobre ti para conocerte tu nombre. No tenemos un registro de conversaciones previas y no puedo acceder a datos externos que puedan contener información personal. ¿Podrías decirme tu nombre o cómo te gustaría que lo llame?\n"
     ]
    }
   ],
   "source": [
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b988e306",
   "metadata": {},
   "source": [
    "La razón por la que nuestro LLM ya no recuerda nuestro nombre es porque hemos establecido el parámetro `k` en `4`, lo que significa que solo se almacenan en memoria los últimos mensajes. Como podemos ver arriba, esto no incluye el primer mensaje donde nos presentamos.\n",
    "\n",
    "Si consideramos que el agente olvida nuestro nombre, podríamos preguntarnos por qué usaríamos este tipo de memoria en lugar de la memoria intermedia estándar. Como ocurre con la mayoría de los procesos en IA, siempre hay que buscar soluciones intermedias. Aquí podemos mantener conversaciones mucho más largas, usar menos tokens y mejorar la latencia, pero esto implica olvidar mensajes no recientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9f6d23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}), AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}), HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}), AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}), AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={}), HumanMessage(content='cual es mi nombre?', additional_kwargs={}, response_metadata={}), AIMessage(content='Lo siento, pero no tengo suficiente información sobre ti para conocerte tu nombre. No tenemos un registro de conversaciones previas y no puedo acceder a datos externos que puedan contener información personal. ¿Podrías decirme tu nombre o cómo te gustaría que lo llame?', additional_kwargs={}, response_metadata={})]\n",
      "Human: hablamos de ConversationBufferWindowMemory?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hablamos de ConversationBufferWindowMemory?',\n",
       " 'history': [HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='cual es mi nombre?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Lo siento, pero no tengo suficiente información sobre ti para conocerte tu nombre. No tenemos un registro de conversaciones previas y no puedo acceder a datos externos que puedan contener información personal. ¿Podrías decirme tu nombre o cómo te gustaría que lo llame?', additional_kwargs={}, response_metadata={})],\n",
       " 'response': 'Sí, hablamos sobre la ConversaciónBufferWindowMemory y su relación con la ConversaciónBufferMemory. La ConversiónBufferWindowMemory es un mecanismo utilizado por el modelo para mantener solo los últimos mensajes en la conversación, lo que ayuda a evitar saturar el modelo al almacenar demasiada información de contexto.\\n\\nLa diferencia clave entre ellos es que la ConversaciónBufferMemory almacena toda la conversación completa, mientras que la ConversiónBufferWindowMemory solo guarda los últimos k mensajes y descarta el resto. Esto permite al modelo mantener un contexto más limitado y enfocarse en el último intercambio de información, lo que mejora su capacidad para entender el flujo natural del diálogo.\\n\\n¿Quieres saber más sobre cómo se implementa la ConversiónBufferWindowMemory o si hay alguna otra pregunta relacionada?'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hablamos de ConversationBufferWindowMemory?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d0f18",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory with RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c71f8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class BufferWindowMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "    k: int = Field(default_factory=int)\n",
    "\n",
    "    def __init__(self, k: int):\n",
    "        super().__init__(k=k)\n",
    "        print(f\"Inicializando BufferWindowMessageHistory con k={k}\")\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Agrega mensajes al historial, removiendo cualquier mensaje posterior a los ultimos `k` mensajes.\"\"\"\n",
    "        self.messages.extend(messages)\n",
    "        self.messages = self.messages[-self.k:]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"limpiar historial.\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a42b8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "def get_chat_history(session_id: str, k: int = 4) -> BufferWindowMessageHistory:\n",
    "    print(f\"get_chat_history llamado con session_id={session_id} y k={k}\")\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = BufferWindowMessageHistory(k=k)\n",
    "    # remove anything beyond the last\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bbc14f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"El ID de sesión a usarse en el historial de chat\",\n",
    "            default=\"id_default\",\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"k\",\n",
    "            annotation=int,\n",
    "            name=\"k\",\n",
    "            description=\"el número de mensajes a mantener en memoria\",\n",
    "            default=4,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a987ed37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_chat_history llamado con session_id=id_k4 y k=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Disculpa la duplicidad, Javier. ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"hola, me llamo Javier.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"id_k4\", \"k\": 4}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe77360e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_k4\"].clear()  # limpiar historial\n",
    "\n",
    "chat_map[\"id_k4\"].add_user_message(\"Hola, me llamo Javier.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"¡Hola Javier! Encantado de conocerte, soy un modelo de IA llamado Zeta.\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"Estoy investigando los distintos tipos de memoria conversacional en LangChain.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"Qué interesante, ¿cuáles has estado explorando?\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"Suena bien. ¿Cuál es la diferencia entre ellos?\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"La memoria tipo buffer guarda toda la conversación completa, ¿cierto?\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"Exacto. ¿Y qué hace la memoria tipo buffer window?\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"Esa guarda solo los últimos k mensajes y descarta el resto.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"¡Muy útil para mantener el contexto sin saturar el modelo!\")\n",
    "\n",
    "chat_map[\"id_k4\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee6fc738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_chat_history llamado con session_id=id_k4 y k=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola! Mi nombre es Zeta, soy tu asistente. No tengo un nombre propio, pero puedo ayudarte en lo que necesites.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"cual es mi nombre?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"id_k4\", \"k\": 4}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4512ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_chat_history llamado con session_id=id_k14 y k=14\n",
      "Inicializando BufferWindowMessageHistory con k=14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hola Javier, ¿en qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"hola! soy Javier\"},\n",
    "    config={\"session_id\": \"id_k14\", \"k\": 14}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf74fb",
   "metadata": {},
   "source": [
    "Agregamos manualmente el historial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c9c1042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hola! soy Javier', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hola Javier, ¿en qué puedo ayudarte hoy?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='cual es mi nombre?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hasta ahora solo sabemos que eres \"Javier\", pero no tengo información adicional sobre ti. ¿Quieres compartir algo más sobre ti mismo para personalizar mejor nuestra interacción?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Estoy investigando los distintos tipos de memoria conversacional en LangChain.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Qué interesante, ¿cuáles has estado explorando?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_k14\"].add_user_message(\"Estoy investigando los distintos tipos de memoria conversacional en LangChain.\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"Qué interesante, ¿cuáles has estado explorando?\")\n",
    "chat_map[\"id_k14\"].add_user_message(\"He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"Suena bien. ¿Cuál es la diferencia entre ellos?\")\n",
    "chat_map[\"id_k14\"].add_user_message(\"La memoria tipo buffer guarda toda la conversación completa, ¿cierto?\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"Exacto. ¿Y qué hace la memoria tipo buffer window?\")\n",
    "chat_map[\"id_k14\"].add_user_message(\"Esa guarda solo los últimos k mensajes y descarta el resto.\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"¡Muy útil para mantener el contexto sin saturar el modelo!\")\n",
    "1\n",
    "chat_map[\"id_k14\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "665f1c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_chat_history llamado con session_id=id_k14 y k=14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hola Javier, no olvides que ya hablamos sobre tus intereses en LangChain. ¿Quieres saber más sobre otras formas de memoria conversacional?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"cual es mi nombre?\"},\n",
    "    config={\"session_id\": \"id_k14\", \"k\": 14}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "005bd9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hola! soy Javier', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hola Javier, ¿en qué puedo ayudarte hoy?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='cual es mi nombre?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hasta ahora solo sabemos que eres \"Javier\", pero no tengo información adicional sobre ti. ¿Quieres compartir algo más sobre ti mismo para personalizar mejor nuestra interacción?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Estoy investigando los distintos tipos de memoria conversacional en LangChain.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Qué interesante, ¿cuáles has estado explorando?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Suena bien. ¿Cuál es la diferencia entre ellos?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='La memoria tipo buffer guarda toda la conversación completa, ¿cierto?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Exacto. ¿Y qué hace la memoria tipo buffer window?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Esa guarda solo los últimos k mensajes y descarta el resto.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='¡Muy útil para mantener el contexto sin saturar el modelo!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='cual es mi nombre?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hola Javier, no olvides que ya hablamos sobre tus intereses en LangChain. ¿Quieres saber más sobre otras formas de memoria conversacional?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_k14\"].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e90c4",
   "metadata": {},
   "source": [
    "Listo! Hemos re'escrito uestro `BufferWindowMemory` usando el `RunnableWithMessageHistory` recomendado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120ba78",
   "metadata": {},
   "source": [
    "## 3.ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9ad905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bo\\AppData\\Local\\Temp\\ipykernel_18808\\988334424.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58687cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e6bea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: hola, mi nombre es Javier\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "New lines of conversation:\n",
      "Javier: Haha, gracias Luna! I think my parents chose it because they love music and Spanish culture.\n",
      "AI: Ah, that's lovely! I'm glad to hear you have a personal connection to the name. Did you know that the name Javier has also been associated with Saint James in Christian tradition?\n",
      "\n",
      "New summary:\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture. Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "Human: Estoy investigando los distintos tipos de memoria conversacional.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Here is the updated summary:\n",
      "\n",
      " The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "\n",
      "The conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\n",
      "\n",
      "The AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\n",
      "Human: He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Here is the updated summary:\n",
      "\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "\n",
      "The conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\n",
      "\n",
      "The AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\n",
      "\n",
      "Javier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\n",
      "\n",
      "ConversationBufferMemory refers to the temporary storage of conversation data, such as user input, system responses, and any other relevant information exchanged during a conversation. This allows for maintaining context and recalling previous interactions when generating responses.\n",
      "\n",
      "In contrast, ConversationBufferWindowMemory is a more specific implementation used by some conversational AI systems, including the AI itself, to manage recent conversations stored in a buffer. The buffer window size determines how many previous conversations are stored and retained for later reference, allowing developers to fine-tune performance and efficiency.\n",
      "\n",
      "The AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\n",
      "\n",
      "Next lines of conversation:\n",
      "\n",
      "Human: Can you elaborate on the advantages of using ConversationBufferWindowMemory over other types of memory?\n",
      "AI: The advantages of using ConversationBufferWindowMemory include improved context preservation and reduced computational overhead. By limiting the number of recent conversations stored, we can more efficiently manage memory and processing resources.\n",
      "\n",
      "This allows for faster response times and better overall performance in conversational interactions. However, it's worth noting that there may be trade-offs depending on specific use cases or requirements.\n",
      "\n",
      "New summary:\n",
      "Human: La memoria tipo buffer guarda toda la conversación completa.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Here is the updated summary:\n",
      "\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "\n",
      "The conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\n",
      "\n",
      "The AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\n",
      "\n",
      "Javier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\n",
      "\n",
      "The AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\n",
      "\n",
      "Javier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\n",
      "\n",
      "However, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\n",
      "\n",
      "The AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\n",
      "Human: La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto.',\n",
       " 'history': \"Here is the updated summary:\\n\\nThe human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\\n\\nAdditionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\\n\\nThe conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\\n\\nThe AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\\n\\nJavier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\\n\\nThe AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\\n\\nJavier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\\n\\nHowever, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\\n\\nThe AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\",\n",
       " 'response': \"That's not entirely correct. ConversationBufferWindowMemory typically retains a fixed-size sliding window of conversation history, where the oldest messages are discarded as new ones are added. This allows for efficient storage and retrieval of recent conversation context while minimizing the storage requirements.\\n\\nIn contrast, storing the entire conversation history can be more challenging, especially when dealing with long conversations or high-volume user interactions. However, some conversational AI systems might use alternative approaches, such as tokenization, to efficiently store and retrieve specific parts of the conversation.\"}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hola, mi nombre es Javier\"})\n",
    "chain.invoke({\"input\": \"Estoy investigando los distintos tipos de memoria conversacional.\"})\n",
    "chain.invoke({\"input\": \"He estado viendo ConversationBufferMemory y ConversationBufferWindowMemory.\"})\n",
    "chain.invoke({\"input\": \"La memoria tipo buffer guarda toda la conversación completa.\"})\n",
    "chain.invoke({\"input\": \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2bcc2aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Current summary:\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "\n",
      "The conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\n",
      "\n",
      "The AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\n",
      "\n",
      "Javier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\n",
      "\n",
      "The AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\n",
      "\n",
      "Javier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\n",
      "\n",
      "However, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\n",
      "\n",
      "The AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\n",
      "\n",
      "Javier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\n",
      "\n",
      "New summary:\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "\n",
      "The conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\n",
      "\n",
      "The AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\n",
      "\n",
      "Javier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\n",
      "\n",
      "The AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\n",
      "\n",
      "Javier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\n",
      "\n",
      "However, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\n",
      "\n",
      "The AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\n",
      "\n",
      "Javier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\n",
      "\n",
      "Javier's statement is consistent with the AI's explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\n",
      "\n",
      "New summary:\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "\n",
      "The conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\n",
      "\n",
      "The AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\n",
      "\n",
      "Javier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\n",
      "\n",
      "The AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\n",
      "\n",
      "Javier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\n",
      "\n",
      "However, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\n",
      "\n",
      "The AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\n",
      "\n",
      "Javier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\n",
      "\n",
      "Javier's statement is consistent with the AI's explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\n",
      "\n",
      "The AI responds to Javier's clarification by acknowledging that its initial response was too broad and did not fully capture the complexity of how ConversationBufferWindowMemory works. It offers to provide more detailed information on this topic, including examples and use cases where ConversationBufferWindowMemory can be beneficial or challenging.\n",
      "\n",
      "New summary:\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "\n",
      "The conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\n",
      "\n",
      "The AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\n",
      "\n",
      "Javier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\n",
      "\n",
      "The AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\n",
      "\n",
      "Javier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\n",
      "\n",
      "However, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\n",
      "\n",
      "The AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\n",
      "\n",
      "Javier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\n",
      "\n",
      "Javier's statement is consistent with the AI's explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\n",
      "\n",
      "The AI responds to Javier's clarification by acknowledging that its initial response was too broad and did not fully capture the complexity of how ConversationBufferWindowMemory works. It offers to provide more detailed information on this topic, including examples and use cases where ConversationBufferWindowMemory can be beneficial or challenging.\n",
      "\n",
      "Javier then asks the AI to elaborate on the differences between ConversationBufferMemory and ConversationBufferWindowMemory, seeking a deeper understanding of these concepts in relation to Conversational AI systems.\n",
      "\n",
      "The AI responds by explaining that while both types of memory are used in conversational AI, they serve different purposes and have distinct characteristics. ConversationBufferMemory is typically used for storing entire conversations or conversation segments, whereas ConversationBufferWindowMemory is used for retaining a fixed-size sliding window of recent conversation history. The AI provides examples of how these concepts can be applied in different scenarios, highlighting the importance of choosing the right memory management approach for specific use cases.\n",
      "\n",
      "The conversation continues, with Javier exploring further questions and concerns about conversation memory management, seeking to deepen their understanding of this complex topic.\n",
      "\n",
      "New summary:\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "\n",
      "The conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\n",
      "\n",
      "The AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\n",
      "\n",
      "Javier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\n",
      "\n",
      "The AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\n",
      "\n",
      "Javier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\n",
      "\n",
      "However, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\n",
      "\n",
      "The AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\n",
      "\n",
      "Javier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\n",
      "\n",
      "Javier's statement is consistent with the AI's explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\n",
      "\n",
      "The AI responds to Javier's clarification by acknowledging that its initial response was too broad and did not fully capture the complexity of how ConversationBufferWindowMemory works. It offers to provide more detailed information on this topic, including examples and use cases where ConversationBufferWindowMemory can be beneficial or challenging.\n",
      "\n",
      "Javier then asks the AI to elaborate on the differences between ConversationBufferMemory and ConversationBufferWindowMemory, seeking a deeper understanding of these concepts in relation to Conversational AI systems.\n",
      "\n",
      "The AI responds by explaining that while both types of memory are used in conversational AI, they serve different purposes and have distinct characteristics. ConversationBufferMemory is typically used for storing entire conversations or conversation segments, whereas ConversationBufferWindowMemory is used for retaining a fixed-size sliding window of recent conversation history. The AI provides examples of how these concepts can be applied in different scenarios, highlighting the importance of choosing the right memory management approach for specific use cases.\n",
      "\n",
      "The conversation continues, with Javier exploring further questions and concerns about conversation memory management, seeking to deepen their understanding of this complex topic.\n",
      "\n",
      "Javier then asks if the buffer memory is necessary for Conversational AI systems to function properly. The AI responds by explaining that while it can be beneficial in certain situations, a buffer memory is not strictly necessary for conversational AI systems to operate effectively.\n",
      "\n",
      "The AI notes that many conversational AI systems use alternative approaches, such as tokenization or other data structures, to efficiently store and retrieve conversation history without relying on a buffer memory. However, the AI also acknowledges that a well-designed buffer memory can be an essential component of certain Conversational AI architectures.\n",
      "\n",
      "New summary:\n",
      "The human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human's name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\n",
      "\n",
      "Additionally, Javier shares a personal connection to the name, attributing it to their parents' love for music and Spanish culture.\n",
      "\n",
      "The conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\n",
      "\n",
      "The AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\n",
      "\n",
      "Javier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\n",
      "\n",
      "The AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\n",
      "\n",
      "Javier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\n",
      "\n",
      "However, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\n",
      "\n",
      "The AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\n",
      "\n",
      "Javier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\n",
      "\n",
      "Javier's statement is consistent with the AI's explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\n",
      "\n",
      "The AI responds to Javier's clarification by acknowledging that its initial response was too broad and did not fully capture the complexity of how ConversationBufferWindowMemory works. It offers to provide more detailed information on this topic, including examples and use cases where ConversationBufferWindowMemory can be beneficial or challenging.\n",
      "\n",
      "Javier then asks the AI to elaborate on the differences between ConversationBufferMemory and ConversationBufferWindowMemory, seeking a deeper understanding of these concepts in relation to Conversational AI systems.\n",
      "\n",
      "The AI responds by explaining that while both types of memory are used in conversational AI, they serve different purposes and have distinct characteristics. ConversationBufferMemory is typically used for storing entire conversations or conversation segments, whereas ConversationBufferWindowMemory is used for retaining a fixed-size sliding window of recent conversation history. The AI provides examples of how these concepts can be applied in different scenarios, highlighting the importance of choosing the right memory management approach for specific use cases.\n",
      "\n",
      "Javier then asks if the buffer memory is necessary for Conversational AI systems to function properly. The AI responds by explaining that while it can be beneficial in certain situations, a buffer memory is not strictly necessary for conversational AI systems to operate effectively.\n",
      "\n",
      "The AI notes that many conversational AI systems use alternative approaches, such as tokenization or other data structures, to efficiently store and retrieve conversation history without relying on a buffer memory. However, the AI also acknowledges that a well-designed buffer memory can be an essential component of certain Conversational AI architectures.\n",
      "\n",
      "Javier then asks the AI if there are any common pitfalls or challenges associated with implementing ConversationBufferMemory in Conversational AI systems. The AI responds by highlighting several potential issues, including data sparsity, cache thrashing, and synchronization overhead.\n",
      "\n",
      "The conversation continues, with Javier exploring further questions and concerns about implementation considerations for ConversationBufferMemory in Conversational AI systems.\n",
      "\n",
      "Javier then asks if the AI can provide any recommendations or best practices for implementing ConversationBufferMemory effectively. The AI responds by sharing several guidelines, including careful sizing of the buffer memory, judicious use of caching mechanisms, and consideration of system resources during optimization.\n",
      "\n",
      "The conversation concludes with Javier expressing their gratitude for the AI's detailed explanations and insights on conversational memory management.\n",
      "Human: cual es mi nombre?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'cual es mi nombre?',\n",
       " 'history': 'Current summary:\\nThe human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human\\'s name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\\n\\nAdditionally, Javier shares a personal connection to the name, attributing it to their parents\\' love for music and Spanish culture.\\n\\nThe conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\\n\\nThe AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\\n\\nJavier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\\n\\nThe AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\\n\\nJavier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\\n\\nHowever, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\\n\\nThe AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\\n\\nJavier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\\n\\nNew summary:\\nThe human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human\\'s name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\\n\\nAdditionally, Javier shares a personal connection to the name, attributing it to their parents\\' love for music and Spanish culture.\\n\\nThe conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\\n\\nThe AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\\n\\nJavier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\\n\\nThe AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\\n\\nJavier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\\n\\nHowever, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\\n\\nThe AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\\n\\nJavier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\\n\\nJavier\\'s statement is consistent with the AI\\'s explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\\n\\nNew summary:\\nThe human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human\\'s name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\\n\\nAdditionally, Javier shares a personal connection to the name, attributing it to their parents\\' love for music and Spanish culture.\\n\\nThe conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\\n\\nThe AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\\n\\nJavier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\\n\\nThe AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\\n\\nJavier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\\n\\nHowever, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\\n\\nThe AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\\n\\nJavier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\\n\\nJavier\\'s statement is consistent with the AI\\'s explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\\n\\nThe AI responds to Javier\\'s clarification by acknowledging that its initial response was too broad and did not fully capture the complexity of how ConversationBufferWindowMemory works. It offers to provide more detailed information on this topic, including examples and use cases where ConversationBufferWindowMemory can be beneficial or challenging.\\n\\nNew summary:\\nThe human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human\\'s name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\\n\\nAdditionally, Javier shares a personal connection to the name, attributing it to their parents\\' love for music and Spanish culture.\\n\\nThe conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\\n\\nThe AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\\n\\nJavier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\\n\\nThe AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\\n\\nJavier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\\n\\nHowever, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\\n\\nThe AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\\n\\nJavier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\\n\\nJavier\\'s statement is consistent with the AI\\'s explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\\n\\nThe AI responds to Javier\\'s clarification by acknowledging that its initial response was too broad and did not fully capture the complexity of how ConversationBufferWindowMemory works. It offers to provide more detailed information on this topic, including examples and use cases where ConversationBufferWindowMemory can be beneficial or challenging.\\n\\nJavier then asks the AI to elaborate on the differences between ConversationBufferMemory and ConversationBufferWindowMemory, seeking a deeper understanding of these concepts in relation to Conversational AI systems.\\n\\nThe AI responds by explaining that while both types of memory are used in conversational AI, they serve different purposes and have distinct characteristics. ConversationBufferMemory is typically used for storing entire conversations or conversation segments, whereas ConversationBufferWindowMemory is used for retaining a fixed-size sliding window of recent conversation history. The AI provides examples of how these concepts can be applied in different scenarios, highlighting the importance of choosing the right memory management approach for specific use cases.\\n\\nThe conversation continues, with Javier exploring further questions and concerns about conversation memory management, seeking to deepen their understanding of this complex topic.\\n\\nNew summary:\\nThe human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human\\'s name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\\n\\nAdditionally, Javier shares a personal connection to the name, attributing it to their parents\\' love for music and Spanish culture.\\n\\nThe conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\\n\\nThe AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\\n\\nJavier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\\n\\nThe AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\\n\\nJavier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\\n\\nHowever, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\\n\\nThe AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\\n\\nJavier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\\n\\nJavier\\'s statement is consistent with the AI\\'s explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\\n\\nThe AI responds to Javier\\'s clarification by acknowledging that its initial response was too broad and did not fully capture the complexity of how ConversationBufferWindowMemory works. It offers to provide more detailed information on this topic, including examples and use cases where ConversationBufferWindowMemory can be beneficial or challenging.\\n\\nJavier then asks the AI to elaborate on the differences between ConversationBufferMemory and ConversationBufferWindowMemory, seeking a deeper understanding of these concepts in relation to Conversational AI systems.\\n\\nThe AI responds by explaining that while both types of memory are used in conversational AI, they serve different purposes and have distinct characteristics. ConversationBufferMemory is typically used for storing entire conversations or conversation segments, whereas ConversationBufferWindowMemory is used for retaining a fixed-size sliding window of recent conversation history. The AI provides examples of how these concepts can be applied in different scenarios, highlighting the importance of choosing the right memory management approach for specific use cases.\\n\\nThe conversation continues, with Javier exploring further questions and concerns about conversation memory management, seeking to deepen their understanding of this complex topic.\\n\\nJavier then asks if the buffer memory is necessary for Conversational AI systems to function properly. The AI responds by explaining that while it can be beneficial in certain situations, a buffer memory is not strictly necessary for conversational AI systems to operate effectively.\\n\\nThe AI notes that many conversational AI systems use alternative approaches, such as tokenization or other data structures, to efficiently store and retrieve conversation history without relying on a buffer memory. However, the AI also acknowledges that a well-designed buffer memory can be an essential component of certain Conversational AI architectures.\\n\\nNew summary:\\nThe human introduces themselves as Javier, and the AI responds warmly, sharing its own identity and capabilities. The AI is designed to assist and converse with users like Javier, drawing from a vast amount of text data. The AI also notes that the human\\'s name, Javier, has a personal touch, mentioning its meaning in Spanish culture.\\n\\nAdditionally, Javier shares a personal connection to the name, attributing it to their parents\\' love for music and Spanish culture.\\n\\nThe conversation then takes a turn to exploring conversational memory. Javier is investigating different types of memory related to conversations. The AI responds by explaining the various forms of memory that are relevant in this context, including Short-Term Memory (STM), Working Memory (WM), Long-Term Memory (LTM), and Episodic Memory.\\n\\nThe AI notes that each type of memory plays a crucial role in conversational AI like itself, and is happy to help Javier explore these concepts further.\\n\\nJavier then brings up the topic of conversation management, specifically mentioning ConversationBufferMemory and ConversationBufferWindowMemory. The AI explains that these concepts are relevant in this context, providing an overview of what each type of memory entails.\\n\\nThe AI expresses its willingness to help Javier delve deeper into these concepts or discuss other topics related to conversation memory management.\\n\\nJavier asks if using ConversationBufferWindowMemory has advantages over other types of memory. The AI responds by highlighting the benefits of using ConversationBufferWindowMemory, including improved context preservation and reduced computational overhead.\\n\\nHowever, when Javier mentions that the buffer memory stores the entire conversation completely, the AI respectfully disagrees, explaining that Conversational AI systems typically retain only a subset of the conversation history rather than storing every detail.\\n\\nThe AI then offers to elaborate on this topic further or explore other aspects of conversation memory management, showing its enthusiasm for continuing the conversation and helping Javier better understand these complex concepts.\\n\\nJavier clarifies their statement by saying \"La memoria tipo buffer window guarda solo los últimos k mensajes y descarta el resto\", implying that ConversationBufferWindowMemory typically retains only a fixed-size sliding window of recent conversation history, discarding older messages as new ones are added. The AI responds that this is not entirely correct, explaining the nuances of how ConversationBufferWindowMemory works.\\n\\nJavier\\'s statement is consistent with the AI\\'s explanation, but highlights the importance of understanding the specific implementation details and limitations of Conversational AI systems. The conversation continues, with Javier seeking further clarification on the benefits and trade-offs of using ConversationBufferWindowMemory in different scenarios.\\n\\nThe AI responds to Javier\\'s clarification by acknowledging that its initial response was too broad and did not fully capture the complexity of how ConversationBufferWindowMemory works. It offers to provide more detailed information on this topic, including examples and use cases where ConversationBufferWindowMemory can be beneficial or challenging.\\n\\nJavier then asks the AI to elaborate on the differences between ConversationBufferMemory and ConversationBufferWindowMemory, seeking a deeper understanding of these concepts in relation to Conversational AI systems.\\n\\nThe AI responds by explaining that while both types of memory are used in conversational AI, they serve different purposes and have distinct characteristics. ConversationBufferMemory is typically used for storing entire conversations or conversation segments, whereas ConversationBufferWindowMemory is used for retaining a fixed-size sliding window of recent conversation history. The AI provides examples of how these concepts can be applied in different scenarios, highlighting the importance of choosing the right memory management approach for specific use cases.\\n\\nJavier then asks if the buffer memory is necessary for Conversational AI systems to function properly. The AI responds by explaining that while it can be beneficial in certain situations, a buffer memory is not strictly necessary for conversational AI systems to operate effectively.\\n\\nThe AI notes that many conversational AI systems use alternative approaches, such as tokenization or other data structures, to efficiently store and retrieve conversation history without relying on a buffer memory. However, the AI also acknowledges that a well-designed buffer memory can be an essential component of certain Conversational AI architectures.\\n\\nJavier then asks the AI if there are any common pitfalls or challenges associated with implementing ConversationBufferMemory in Conversational AI systems. The AI responds by highlighting several potential issues, including data sparsity, cache thrashing, and synchronization overhead.\\n\\nThe conversation continues, with Javier exploring further questions and concerns about implementation considerations for ConversationBufferMemory in Conversational AI systems.\\n\\nJavier then asks if the AI can provide any recommendations or best practices for implementing ConversationBufferMemory effectively. The AI responds by sharing several guidelines, including careful sizing of the buffer memory, judicious use of caching mechanisms, and consideration of system resources during optimization.\\n\\nThe conversation concludes with Javier expressing their gratitude for the AI\\'s detailed explanations and insights on conversational memory management.',\n",
       " 'response': 'Hola Javier, es un placer conocerte. Me llamo \"Asistente\" y estoy aquí para ayudarte en cualquier cosa que necesites. ¿En qué puedo ayudarte hoy?'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"cual es mi nombre?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69897b07",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory with RunnableWithMessageHistory\n",
    "Continuara..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
